def MakeDataClean(data):
    """
    Cleans the input DataFrame by:
    - Converting 'Date' columns to datetime type
    - Converting string columns to numeric where possible
    - Dropping duplicate rows
    - Handling missing values with appropriate strategies
    - Removing outliers using IQR and filling nulls intelligently

    Parameters:
    data (pd.DataFrame): Input raw DataFrame

    Returns:
    pd.DataFrame: Cleaned DataFrame with no nulls
    """

    # Make a copy of the data to avoid modifying the original
    data_copy = data.copy()

    numeric_cols = []

    # Convert 'Date' column to datetime if present
    if 'Date' in data_copy.columns:
        data_copy['Date'] = pd.to_datetime(data_copy['Date'], dayfirst=True)

    # Convert object columns to numeric if more than 80% values are numeric
    for col in data_copy.columns:
        if data_copy[col].dtype == 'object':
            num_numeric = pd.to_numeric(data_copy[col], errors='coerce').notnull().sum()
            tot = len(data_copy[col])
            if (num_numeric / tot > 0.8):
                data_copy[col] = pd.to_numeric(data_copy[col], errors='coerce')
            else:
                data_copy[col] = data_copy[col].str.strip()
        else:
            numeric_cols.append(col)

    # Remove duplicate rows
    data_copy.drop_duplicates(inplace=True)

    null_cols = []

    # Collect columns with significant nulls for special processing
    for col in data_copy.columns[data_copy.isnull().sum() > 0]:
        if data_copy[col].isnull().sum() <= 5:
            data_copy.dropna(subset=[col], inplace=True)
        else:
            null_cols.append(col)

    # List of categorical columns with no nulls
    cat_cols = []
    for col in data_copy.columns:
        if data_copy[col].dtype == 'object' and data_copy[col].isnull().sum() == 0:
            cat_cols.append(col)

    # Process each column with significant nulls
    for col in null_cols:
        if data_copy[col].dtype != 'object':
            # Outlier detection using IQR
            Q1 = data_copy[col].quantile(0.25)
            Q3 = data_copy[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            # Calculate percentage of outliers
            percent = ((data_copy[col] < lower_bound).sum() + (data_copy[col] > upper_bound).sum()) / data_copy.shape[0] * 100
            
            # Clip outliers
            data_copy[col] = np.clip(data_copy[col], lower_bound, upper_bound)

            # Attempt filling nulls by reducing cat_cols one by one
            temp_cat_cols = cat_cols.copy()
            while data_copy[col].isnull().sum() > 0 and len(temp_cat_cols) > 0:
                if (percent < 2):
                    data_copy[col] = data_copy[col].fillna(
                        value=data_copy.groupby(temp_cat_cols)[col].transform(lambda x: x.fillna(x.mean()))
                    )
                    temp_cat_cols.pop()
                else:
                    data_copy[col] = data_copy[col].fillna(
                        value=data_copy.groupby(temp_cat_cols)[col].transform(lambda x: x.fillna(x.median()))
                    )
                    temp_cat_cols.pop()

        else:
            # For object columns, fill nulls intelligently by grouping
            temp_cat_cols = cat_cols.copy()
            while data_copy[col].isnull().sum() > 0 and len(temp_cat_cols) > 0:
                data_copy[col] = data_copy[col].fillna(
                    value=data_copy.groupby(temp_cat_cols)[col].transform(lambda x: x.fillna(x.mode()))
                )
                temp_cat_cols.pop()

    return data_copy
